---
title: "大數據分析方法"
author: "曾意儒 Yi-Ju Tseng, 長庚大學資管系"
date: "April 11, 2016"
output: ioslides_presentation
subtitle: "Analytic Graphics"
highlighter: highlight.js
---


## 複習

##每次開始前
- 打開GitHub桌面版
- 打GitHub帳密與Git config資料
- **Clone**上次交的作業回本機端(存到桌面)
+ 提示：左上角的+號，選**Clone**
- 點兩下*Clone回來的資料夾*裡面的**.Rproj**




## Principles of Analytic Graphics

* Principle 1: Show comparisons

  - Evidence for a hypothesis is always *relative* to another competing
    hypothesis.

  - Always ask "Compared to What?"

---

## Show Comparisons

```{r,echo=FALSE,fig.width=6,fig.height=6.5}
setwd("~/projects/PREACH")
source("regmodel.R")
with(subset(dd, group == 1), boxplot(diffsymfree, xaxt = "n", ylab = "Change in symptom-free days"))
axis(1, 1, "Air Cleaner")
abline(h = 0, lty = 3, lwd = 1.5)
```

Reference: Butz AM, *et al.*, *JAMA Pediatrics*, 2011.

---

## Show Comparisons

```{r,echo=FALSE,fig.width=6,fig.height=6.5}
setwd("~/projects/PREACH")
source("regmodel.R")
boxplot(diffsymfree ~ group, dd, xaxt = "n", ylab = "Change in symptom-free days")
axis(1, 1:2, c("Control", "Air Cleaner"))
abline(h = 0, lty = 3, lwd = 1.5)
```

Reference: Butz AM, *et al.*, *JAMA Pediatrics*, 2011.

---

## Principles of Analytic Graphics

* Principle 1: Show comparisons

  - Evidence for a hypothesis is always *relative* to another competing
    hypothesis.

  - Always ask "Compared to What?"

* Principle 2: Show causality, mechanism, explanation, systematic structure 
  - What is your causal framework for thinking about a question?

---

## Show causality, mechanism

```{r,echo=FALSE,fig.width=6,fig.height=6.5}
setwd("~/projects/PREACH")
source("regmodel.R")
boxplot(diffsymfree ~ group, dd, xaxt = "n", ylab = "Change in symptom-free days", main = "Symptom-free Days")
axis(1, 1:2, c("Control", "Air Cleaner"))
abline(h = 0, lty = 3, lwd = 1.5)
```

Reference: Butz AM, *et al.*, *JAMA Pediatrics*, 2011.

---
## Show causality, mechanism

```{r,echo=FALSE,fig.width = 12, fig.height=6.5}
setwd("~/projects/PREACH")
source("regmodel.R")
par(mfrow = c(1, 2))
ddm$group <- factor(ddm$group, labels = c("Control", "Air Cleaner"))
boxplot(diffsymfree ~ group, ddm, ylab = "Change in symptom-free days", main = "Symptom-free Days")
abline(h = 0, lty = 3, lwd = 1.5)
boxplot(diffpm25 ~ group, ddm, ylab = expression("Change in " * PM[2.5]), main = "Fine Particulate Matter")
abline(h = 0, lty = 3, lwd = 1.5)
```

Reference: Butz AM, *et al.*, *JAMA Pediatrics*, 2011.

---

## Principles of Analytic Graphics

* Principle 1: Show comparisons

  - Evidence for a hypothesis is always *relative* to another competing
    hypothesis.

  - Always ask "Compared to What?"

* Principle 2: Show causality, mechanism, explanation, systematic structure 
  - What is your causal framework for thinking about a question?

* Principle 3: Show multivariate data
  - Multivariate = more than 2 variables 
  - The real world is multivariate
  - Need to "escape flatland"

---

## Show Multivariate Data

```{r,echo=FALSE,fig.height=6,warning=FALSE,message=FALSE}
setwd("~/projects/nmmaps1987_2005")
suppressPackageStartupMessages(library(tsModel))
d <- readRDS("ny.rds")
d <- subset(d, date < as.Date("2001-01-01"))
dout <- d[, c("date", "death")]
dout <- aggregate(d[, "death", drop = FALSE], list(d[, "date"]), sum)
names(dout)[1] <- "date"
pm <- unique(d[, c("pm10tmean", "date")])
pm$pm10 <- with(pm, Lag(pm10tmean, 1))
m <- merge(dout, pm, by = "date")

library(ggplot2)
qplot(pm10, death, data = m, geom = c("point", "smooth"), method = "lm", xlab = expression(PM[10] * " concentration (centered)"), ylab = "Daily mortality (all cuases)")
```

---
## Show Multivariate Data

```{r,echo=FALSE,fig.width=14,fig.height=6,warning=FALSE,message=FALSE}
setwd("~/projects/nmmaps1987_2005")
suppressPackageStartupMessages(library(tsModel))
d <- readRDS("ny.rds")
d <- subset(d, date < as.Date("2001-01-01"))
dout <- d[, c("date", "death")]
dout <- aggregate(d[, "death", drop = FALSE], list(d[, "date"]), sum)
names(dout)[1] <- "date"
pm <- unique(d[, c("pm10tmean", "date")])
pm$pm10 <- with(pm, Lag(pm10tmean, 1))
m <- merge(dout, pm, by = "date")
m$season <- factor(quarters(m$date), labels = c("Winter", "Spring", "Summer", "Fall"))

library(ggplot2)
qplot(pm10, death, data = m, facets = . ~ season, geom = c("point", "smooth"), method = "lm", xlab = expression(PM[10] * " concentration (centered)"), ylab = "Daily mortality (all cuases)")
```

---

## Principles of Analytic Graphics

* Principle 4: Integration of evidence
  - Completely integrate words, numbers, images, diagrams

  - Data graphics should make use of many modes of data presentation 

  - Don't let the tool drive the analysis

---

## Integrate Different Modes of Evidence

<img src="../../assets/img/coarsePMCVD.png" height="500" />

---

## Principles of Analytic Graphics

* Principle 4: Integration of evidence
  - Completely integrate words, numbers, images, diagrams

  - Data graphics should make use of many modes of data presentation 

  - Don't let the tool drive the analysis

* Principle 5: Describe and document the evidence with appropriate
  labels, scales, sources, etc.

  - A data graphic should tell a complete story that is credible 


---

## Principles of Analytic Graphics

* Principle 4: Integration of evidence
  - Completely integrate words, numbers, images, diagrams

  - Data graphics should make use of many modes of data presentation 

  - Don't let the tool drive the analysis

* Principle 5: Describe and document the evidence with appropriate
  labels, scales, sources, etc.

  - A data graphic should tell a complete story that is credible 

* Principle 6: Content is king

  - Analytical presentations ultimately stand or fall depending on the
    quality, relevance, and integrity of their content

---

## Summary

* Principle 1: Show comparisons
* Principle 2: Show causality, mechanism, explanation
* Principle 3: Show multivariate data
* Principle 4: Integrate multiple modes of evidence
* Principle 5: Describe and document the evidence
* Principle 6: Content is king

---

## References

Edward Tufte (2006). *Beautiful Evidence*, Graphics Press LLC. [www.edwardtufte.com](http://www.edwardtufte.com)



## The Base Plotting System

* "Artist's palette" model
* Start with blank canvas and build up from there
* Start with plot function (or similar)

* Use annotation functions to add/modify (`text`, `lines`, `points`,
  `axis`)

---

## The Base Plotting System

* Convenient, mirrors how we think of building plots and analyzing data

* Can’t go back once plot has started (i.e. to adjust margins); need
  to plan in advance

* Difficult to "translate" to others once a new plot has been created
  (no graphical "language")

* Plot is just a series of R commands

---

## Base Plot

```{r,fig.height=5,fig.width=5}
library(datasets)
data(cars)
with(cars, plot(speed, dist))
```

---

## The Lattice System

* Plots are created with a single function call (`xyplot`, `bwplot`,
etc.)

* Most useful for conditioning types of plots: Looking at how y changes with x across levels of z

* Things like margins/spacing set automatically because entire plot is
  specified at once

*  Good for puttng many many plots on a screen

---

## The Lattice System

* Sometimes awkward to specify an entire plot in a single function call

* Annotation in plot is not especially intuitive

* Use of panel functions and subscripts difficult to wield and
  requires intense preparation

* Cannot "add" to the plot once it is created

---

## Lattice Plot

```{r,fig.height=4,fig.width=12}
library(lattice)
state <- data.frame(state.x77, region = state.region)
xyplot(Life.Exp ~ Income | region, data = state, layout = c(4, 1))
```

---

## The ggplot2 System

* Splits the difference between base and lattice in a number of ways

* Automatically deals with spacings, text, titles but also allows you
  to annotate by "adding" to a plot

* Superficial similarity to lattice but generally easier/more
  intuitive to use

* Default mode makes many choices for you (but you can still customize
  to your heart's desire)


---

## ggplot2 Plot

```{r, message=FALSE,fig.height=5,fig.width=6}
library(ggplot2)
data(mpg)
qplot(displ, hwy, data = mpg)
```

---

## Summary

* Base: "artist's palette" model

* Lattice: Entire plot specified by one function; conditioning

* ggplot2: Mixes elements of Base and Lattice

---

## References

Paul Murrell (2011). *R Graphics*, CRC Press.

Hadley Wickham (2009). *ggplot2*, Springer.


## Why do we use graphs in data analysis? 

* To understand data properties
* To find patterns in data
* To suggest modeling strategies
* To "debug" analyses
* To communicate results

---

## Exploratory graphs

* <redtext>To understand data properties</redtext>
* <redtext>To find patterns in data</redtext>
* <redtext>To suggest modeling strategies</redtext>
* <redtext>To "debug" analyses</redtext>
* To communicate results

---

## Characteristics of exploratory graphs

* They are made quickly
* A large number are made
* The goal is for personal understanding
* Axes/legends are generally cleaned up (later)
* Color/size are primarily used for information

---

## Air Pollution in the United States

* The U.S. Environmental Protection Agency (EPA) sets national ambient
  air quality standards for outdoor air pollution

  * [U.S. National Ambient Air Quality Standards](http://www.epa.gov/air/criteria.html)

* For fine particle pollution (PM2.5), the "annual mean, averaged over
  3 years" cannot exceed $12~\mu g/m^3$.

* Data on daily PM2.5 are available from the U.S. EPA web site

  - [EPA Air Quality System](http://www.epa.gov/ttn/airs/airsaqs/detaildata/downloadaqsdata.htm)

* **Question**: Are there any counties in the U.S. that exceed that
  national standard for fine particle pollution?

---

## Data

Annual average PM2.5 averaged over the period 2008 through 2010

```{r readpm25data}
pollution <- read.csv("data/avgpm25.csv", colClasses = c("numeric", "character", "factor", "numeric", "numeric"))
head(pollution)
```

Do any counties exceed the standard of $12~\mu g/m^3$?

---

## Simple Summaries of Data


One dimension

* Five-number summary
* Boxplots
* Histograms
* Density plot
* Barplot

---

## Five Number Summary

```{r}
summary(pollution$pm25)
```

---

## Boxplot

```{r}
boxplot(pollution$pm25, col = "blue")
```

---

## Histogram

```{r,fig.height=5}
hist(pollution$pm25, col = "green")
```

---

## Histogram

```{r,fig.height=5}
hist(pollution$pm25, col = "green")
rug(pollution$pm25)
```

---

## Histogram

```{r,fig.height=5}
hist(pollution$pm25, col = "green", breaks = 100)
rug(pollution$pm25)
```

---

## Overlaying Features

```{r}
boxplot(pollution$pm25, col = "blue")
abline(h = 12)
```


---

## Overlaying Features

```{r,fig.height=5}
hist(pollution$pm25, col = "green")
abline(v = 12, lwd = 2)
abline(v = median(pollution$pm25), col = "magenta", lwd = 4)
```

---

## Barplot

```{r}
barplot(table(pollution$region), col = "wheat", main = "Number of Counties in Each Region")
```

---

## Simple Summaries of Data

Two dimensions

* Multiple/overlayed 1-D plots (Lattice/ggplot2)
* Scatterplots
* Smooth scatterplots

$> 2$ dimensions

* Overlayed/multiple 2-D plots; coplots
* Use color, size, shape to add dimensions
* Spinning plots
* Actual 3-D plots (not that useful)


---

## Multiple Boxplots

```{r}
boxplot(pm25 ~ region, data = pollution, col = "red")
```

---

## Multiple Histograms

```{r,fig.width=8,fig.height=5}
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
hist(subset(pollution, region == "east")$pm25, col = "green")
hist(subset(pollution, region == "west")$pm25, col = "green")
```

---

## Scatterplot

```{r,fig.height=6}
with(pollution, plot(latitude, pm25))
abline(h = 12, lwd = 2, lty = 2)
```

---

## Scatterplot - Using Color

```{r,fig.height=6}
with(pollution, plot(latitude, pm25, col = region))
abline(h = 12, lwd = 2, lty = 2)
```

---

## Multiple Scatterplots

```{r,fig.height=5.5,fig.width=12}
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1))
with(subset(pollution, region == "west"), plot(latitude, pm25, main = "West"))
with(subset(pollution, region == "east"), plot(latitude, pm25, main = "East"))
```

---

## Summary

* Exploratory plots are "quick and dirty"

* Let you summarize the data (usually graphically) and highlight any broad features

* Explore basic questions and hypotheses (and perhaps rule them out)

* Suggest modeling strategies for the "next step"

---


## Further resources

* [R Graph Gallery](http://gallery.r-enthusiasts.com/)
* [R Bloggers](http://www.r-bloggers.com/)



## Plotting System

The core plotting and graphics engine in R is encapsulated in the
following packages:

- *graphics*: contains plotting functions for the "base" graphing
   systems, including `plot`, `hist`, `boxplot` and many others.

- *grDevices*: contains all the code implementing the various graphics
   devices, including X11, PDF, PostScript, PNG, etc.

The lattice plotting system is implemented using the following packages:

- *lattice*: contains code for producing Trellis graphics, which are
   independent of the “base” graphics system; includes functions like
   `xyplot`, `bwplot`, `levelplot`

- *grid*: implements a different graphing system independent of the
   “base” system; the *lattice* package builds on top of *grid*; we
   seldom call functions from the *grid* package directly

---

## The Process of Making a Plot

When making a plot one must first make a few considerations (not
necessarily in this order):

- Where will the plot be made? On the screen? In a file? 

<!--
  - The default in Unix is `x11`; on Windows it is `windows`; on Mac
    OS X it is `quartz`
-->

- How will the plot be used?
  - Is the plot for viewing temporarily on the screen?  
  - Will it be presented in a web browser?
  - Will it eventually end up in a paper that might be printed? 
  - Are you using it in a presentation?

- Is there a large amount of data going into the plot? Or is it just a
  few points?

- Do you need to be able to dynamically resize the graphic?

---

## The Process of Making a Plot

- What graphics system will you use: base, lattice, or ggplot2? These
  generally cannot be mixed.

- Base graphics are usually constructed piecemeal, with each aspect of
  the plot handled separately through a series of function calls; this
  is often conceptually simpler and allows plotting to mirror the
  thought process

- Lattice graphics are usually created in a single function call, so
  all of the graphics parameters have to specified at once; specifying
  everything at once allows R to automatically calculate the necessary
  spacings and font sizes.

- ggplot2 combines concepts from both base and lattice graphics but
  uses an independent implementation

We focus on using the **base plotting system** to create graphics on
the **screen device**.

---

## Base Graphics

Base graphics are used most commonly and are a very powerful system for creating 2-D graphics.

- There are two *phases* to creating a base plot
  - Initializing a new plot
  - Annotating (adding to) an existing plot

- Calling `plot(x, y)` or `hist(x)` will launch a graphics device (if
  one is not already open) and draw a new plot on the device

- If the arguments to `plot` are not of some special class, then the
  _default_ method for `plot` is called; this function has _many_
  arguments, letting you set the title, x axis label, y axis label,
  etc.

- The base graphics system has _many_ parameters that can set and
  tweaked; these parameters are documented in `?par`; it wouldn’t hurt
  to try to memorize this help page!

---

## Simple Base Graphics: Histogram

```{r,fig.height=5}
library(datasets)
hist(airquality$Ozone)  ## Draw a new plot
```

---

## Simple Base Graphics: Scatterplot

```{r,fig.height=5}
library(datasets)
with(airquality, plot(Wind, Ozone))
```

---

## Simple Base Graphics: Boxplot

```{r,fig.height=5}
library(datasets)
airquality <- transform(airquality, Month = factor(Month))
boxplot(Ozone ~ Month, airquality, xlab = "Month", ylab = "Ozone (ppb)")
```
---


## Some Important Base Graphics Parameters

Many base plotting functions share a set of parameters. Here are a few
key ones:

- `pch`: the plotting symbol (default is open circle)

- `lty`: the line type (default is solid line), can be dashed, dotted, etc.

- `lwd`: the line width, specified as an integer multiple

- `col`: the plotting color, specified as a number, string, or hex
  code; the `colors()` function gives you a vector of colors by name

- `xlab`: character string for the x-axis label

- `ylab`: character string for the y-axis label


---

## Some Important Base Graphics Parameters

The `par()` function is used to specify *global* graphics parameters
that affect all plots in an R session. These parameters can be
overridden when specified as arguments to specific plotting functions.

- `las`: the orientation of the axis labels on the plot
- `bg`: the background color
- `mar`: the margin size
- `oma`: the outer margin size (default is 0 for all sides)
- `mfrow`: number of plots per row, column (plots are filled row-wise) 
- `mfcol`: number of plots per row, column (plots are filled column-wise)

---

## Some Important Base Graphics Parameters

Default values for global graphics parameters

```{r}
par("lty")
par("col")
par("pch")
```

---

## Some Important Base Graphics Parameters

Default values for global graphics parameters

```{r}
par("bg")
par("mar")
par("mfrow")
```

---

## Base Plotting Functions

- `plot`: make a scatterplot, or other type of plot depending on the
  class of the object being plotted

- `lines`: add lines to a plot, given a vector x values and a
  corresponding vector of y values (or a 2-column matrix); this
  function just connects the dots

- `points`: add points to a plot
- `text`: add text labels to a plot using specified x, y coordinates
- `title`: add annotations to x, y axis labels, title, subtitle, outer margin 
- `mtext`: add arbitrary text to the margins (inner or outer) of the plot 
- `axis`: adding axis ticks/labels

---

## Base Plot with Annotation

```{r,fig.height=5}
library(datasets)
with(airquality, plot(Wind, Ozone))
title(main = "Ozone and Wind in New York City")  ## Add a title
```

---

## Base Plot with Annotation

```{r,fig.height=5}
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
```

---

## Base Plot with Annotation

```{r,fig.height=5}
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", type = "n"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
with(subset(airquality, Month != 5), points(Wind, Ozone, col = "red"))
legend("topright", pch = 1, col = c("blue", "red"), legend = c("May", "Other Months"))
```

---

## Base Plot with Regression Line

```{r,fig.height=5}
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", pch = 20))
model <- lm(Ozone ~ Wind, airquality)
abline(model, lwd = 2)
```

---

## Multiple Base Plots

```{r,fig.height=5,fig.width=14}
par(mfrow = c(1, 2))
with(airquality, {
	plot(Wind, Ozone, main = "Ozone and Wind")
	plot(Solar.R, Ozone, main = "Ozone and Solar Radiation")
})
```

---

## Multiple Base Plots

```{r,fig.height=4,fig.width=12}
par(mfrow = c(1, 3), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))
with(airquality, {
	plot(Wind, Ozone, main = "Ozone and Wind")
	plot(Solar.R, Ozone, main = "Ozone and Solar Radiation")
	plot(Temp, Ozone, main = "Ozone and Temperature")
	mtext("Ozone and Weather in New York City", outer = TRUE)
})
```

---

## Summary

* Plots in the base plotting system are created by calling successive
  R functions to "build up" a plot

* Plotting occurs in two stages:
  - Creation of a plot
  - Annotation of a plot (adding lines, points, text, legends)

* The base plotting system is very flexible and offers a high degree
  of control over plotting



## The Lattice Plotting System

The lattice plotting system is implemented using the following packages:

- *lattice*: contains code for producing Trellis graphics, which are
   independent of the “base” graphics system; includes functions like
   `xyplot`, `bwplot`, `levelplot`

- *grid*: implements a different graphing system independent of the
   “base” system; the *lattice* package builds on top of *grid*
   - We seldom call functions from the *grid* package directly

- The lattice plotting system does not have a "two-phase" aspect with
  separate plotting and annotation like in base plotting

- All plotting/annotation is done at once with a single function call


---

## Lattice Functions

- `xyplot`: this is the main function for creating scatterplots 
- `bwplot`: box-and-whiskers plots (“boxplots”)
- `histogram`: histograms
- `stripplot`: like a boxplot but with actual points 
- `dotplot`: plot dots on "violin strings"
- `splom`: scatterplot matrix; like `pairs` in base plotting system 
- `levelplot`, `contourplot`: for plotting "image" data

---

## Lattice Functions

Lattice functions generally take a formula for their first argument, usually of the form

```r
xyplot(y ~ x | f * g, data)
```

- We use the *formula notation* here, hence the `~`.

- On the left of the ~ is the y-axis variable, on the right is the
  x-axis variable

- f and g are _conditioning variables_ — they are optional
  - the * indicates an interaction between two variables

- The second argument is the data frame or list from which the
  variables in the formula should be looked up

  - If no data frame or list is passed, then the parent frame is used.

- If no other arguments are passed, there are defaults that can be used.

---
## Simple Lattice Plot

```{r,fig.height=5}
library(lattice)
library(datasets)
## Simple scatterplot
xyplot(Ozone ~ Wind, data = airquality)
```

---

## Simple Lattice Plot

```{r,fig.width=12,fig.height=4}
library(datasets)
library(lattice)
## Convert 'Month' to a factor variable
airquality <- transform(airquality, Month = factor(Month)) 
xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(5, 1))
```

---

## Lattice Behavior

Lattice functions behave differently from base graphics functions in
one critical way.

- Base graphics functions plot data directly to the graphics device
  (screen, PDF file, etc.)

- Lattice graphics functions return an object of class **trellis**

- The print methods for lattice functions actually do the work of
  plotting the data on the graphics device.

- Lattice functions return "plot objects" that can, in principle, be
  stored (but it’s usually better to just save the code + data).

- On the command line, trellis objects are *auto-printed* so that it
  appears the function is plotting the data

---

## Lattice Behavior

```{r,fig.height=4,fig.width=5}
p <- xyplot(Ozone ~ Wind, data = airquality)  ## Nothing happens!
print(p)  ## Plot appears
```
```{r,eval=FALSE}
xyplot(Ozone ~ Wind, data = airquality)  ## Auto-printing
```

---

## Lattice Panel Functions

* Lattice functions have a **panel function** which controls what
  happens inside each panel of the plot.

* The *lattice* package comes with default panel functions, but you
  can supply your own if you want to customize what happens in each
  panel

* Panel functions receive the x/y coordinates of the data points
  in their panel (along with any optional arguments)


---

## Lattice Panel Functions

```{r,fig.height=4,fig.width=8}
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x+ rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x | f, layout = c(2, 1))  ## Plot with 2 panels
```

---

## Lattice Panel Functions

```{r,fig.height=4}
## Custom panel function
xyplot(y ~ x | f, panel = function(x, y, ...) {
       panel.xyplot(x, y, ...)  ## First call the default panel function for 'xyplot'
       panel.abline(h = median(y), lty = 2)  ## Add a horizontal line at the median
})
```

---

## Lattice Panel Functions: Regression line

```{r,fig.height=4}
## Custom panel function
xyplot(y ~ x | f, panel = function(x, y, ...) {
               panel.xyplot(x, y, ...)  ## First call default panel function
               panel.lmline(x, y, col = 2)  ## Overlay a simple linear regression line
       })
```

---

## Many Panel Lattice Plot: Example from MAACS

* Study: Mouse Allergen and Asthma Cohort Study (MAACS)

* Study subjects: Children with asthma living in Baltimore City, many
  allergic to mouse allergen

* Design: Observational study, baseline home visit + every 3 months for a year.

* Question: How does indoor airborne mouse allergen vary over time and
  across subjects?


[Ahluwalia et al., *Journal of Allergy and Clinical Immunology*, 2013](http://www.ncbi.nlm.nih.gov/pubmed/23810154)

---

## Many Panel Lattice Plot

```{r,echo=FALSE,cache=TRUE,fig.width=12}
library(lattice)
env <- readRDS("maacs_env.rds")
env <- transform(env, MxNum = factor(MxNum))
xyplot(log2(airmus) ~ VisitNum | MxNum, data = env, strip = FALSE, pch = 20, xlab = "Visit Number", ylab = expression(Log[2] * " Airborne Mouse Allergen"), main = "Mouse Allergen and Asthma Cohort Study (Baltimore City)")
```

---

## Summary

* Lattice plots are constructed with a single function call to a core
  lattice function (e.g. `xyplot`)

* Aspects like margins and spacing are automatically handled and
  defaults are usually sufficient

* The lattice system is ideal for creating conditioning plots where
  you examine the same kind of plot under many different conditions

* Panel functions can be specified/customized to modify what is
  plotted in each of the plot panels


```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# make this an external chunk that can be included in any file
options(width = 80)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/', fig.height = 4, cache = TRUE, fig.show = 'hold')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```

## What is ggplot2?

- An implementation of _The Grammar of Graphics_ by Leland Wilkinson
- Written by Hadley Wickham (while he was a graduate student at Iowa State)
- A “third” graphics system for R (along with __base__ and __lattice__)
- Available from CRAN via `install.packages()`
- Web site: http://ggplot2.org (better documentation)

---

## What is ggplot2?

- Grammar of graphics represents an abstraction of graphics ideas/objects
- Think “verb”, “noun”, “adjective” for graphics
- Allows for a “theory” of graphics on which to build new graphics and graphics objects
- “Shorten the distance from mind to page”

---

## Grammer of Graphics

### “In brief, the grammar tells us that a statistical graphic is a __mapping__ from data to __aesthetic__ attributes (colour, shape, size) of __geometric__ objects (points, lines, bars). The plot may also contain statistical transformations of the data and is drawn on a specific coordinate system”

- from _ggplot2_ book

---

## Plotting Systems in R: Base

- “Artist’s palette” model
- Start with blank canvas and build up from there
- Start with `plot` function (or similar)
- Use annotation functions to add/modify (`text`, `lines`, `points`, `axis`)

---

## Plotting Systems in R: Base

- Convenient, mirrors how we think of building plots and analyzing data
- Can’t go back once plot has started (i.e. to adjust margins); need to plan in advance
- Difficult to “translate” to others once a new plot has been created (no graphical “language”)
  - Plot is just a series of R commands

---

## Plotting Systems in R: Lattice

- Plots are created with a single function call (`xyplot`, `bwplot`, etc.)
- Most useful for conditioning types of plots: Looking at how $y$ changes with $x$ across levels of $z$
- Things like margins/spacing set automatically because entire plot is specified at once
- Good for putting many many plots on a screen

---

## Plotting Systems in R: Lattice

- Sometimes awkward to specify an entire plot in a single function call
- Annotation in plot is not intuitive
- Use of panel functions and subscripts difficult to wield and requires intense preparation
- Cannot “add” to the plot once it’s created

---

## Plotting Systems in R: ggplot2

- Split the difference between base and lattice
- Automatically deals with spacings, text, titles but also allows you to annotate by “adding”
- Superficial similarity to lattice but generally easier/more intuitive to use
- Default mode makes many choices for you (but you _can_ customize!)

---

## The Basics: `qplot()`

- Works much like the `plot` function in base graphics system
- Looks for data in a data frame, similar to lattice, or in the parent environment
- Plots are made up of _aesthetics_ (size, shape, color) and _geoms_ (points, lines)

---

## The Basics: `qplot()`

- Factors are important for indicating subsets of the data (if they are to have different properties); they should be __labeled__
- The `qplot()` hides what goes on underneath, which is okay for most operations
- `ggplot()` is the core function and very flexible for doing things `qplot()` cannot do

---

## Example Dataset

```{r}
library(ggplot2)
str(mpg)
```


---

## ggplot2 “Hello, world!”

```{r}
qplot(displ, hwy, data = mpg)
```

---

## Modifying aesthetics

```{r}
qplot(displ, hwy, data = mpg, color = drv)

```


---

## Adding a geom

```{r}
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))

```

---

## Histograms

```{r}
qplot(hwy, data = mpg, fill = drv)

```



---

## Facets

```{r, fig.width=4.5}
qplot(displ, hwy, data = mpg, facets = . ~ drv)
qplot(hwy, data = mpg, facets = drv ~ ., binwidth = 2)
```

---

## MAACS Cohort

- Mouse Allergen and Asthma Cohort Study
- Baltimore children (aged 5—17)
- Persistent asthma, exacerbation in past year
- Study indoor environment and its relationship with asthma morbidity
- Recent publication: http://goo.gl/WqE9j8

```{r,echo=FALSE}
eno <- read.csv("eno.csv")
skin <- read.csv("skin.csv")
env <- read.csv("environmental.csv")
m <- merge(eno, env, by = "id")
maacs <- merge(m, skin, by = "id")
```

---

## Example: MAACS

```{r}
str(maacs)
```


---

## Histogram of eNO

```{r}
qplot(log(eno), data = maacs)
```

---

## Histogram by Group

```{r}
qplot(log(eno), data = maacs, fill = mopos)
```

---

## Density Smooth

```{r, fig.width=4.5}
qplot(log(eno), data = maacs, geom = "density")
qplot(log(eno), data = maacs, geom = "density", color = mopos)
```

---

## Scatterplots: eNO vs. PM$_{2.5}$

```{r, fig.width=2.7}
qplot(log(pm25), log(eno), data = maacs)
qplot(log(pm25), log(eno), data = maacs, shape = mopos)
qplot(log(pm25), log(eno), data = maacs, color = mopos)
```


---

## Scatterplots: eNO vs. PM$_{2.5}$

```{r}
qplot(log(pm25), log(eno), data = maacs, color = mopos, 
      geom = c("point", "smooth"), method = "lm")
```


---

## Scatterplots: eNO vs. PM$_{2.5}$

```{r, fig.width=9}
qplot(log(pm25), log(eno), data = maacs, geom = c("point", "smooth"), 
      method = "lm", facets = . ~ mopos)
```


---

## Summary of qplot()

- The `qplot()` function is the analog to `plot()` but with many built-in features
- Syntax somewhere in between base/lattice
- Produces very nice graphics, essentially publication ready (if you like the design)
- Difficult to go against the grain/customize (don’t bother; use full ggplot2 power in that case)

---

## Resources

- The _ggplot2_ book by Hadley Wickham
- The _R Graphics Cookbook_ by Winston Chang (examples in base plots and in ggplot2)
- ggplot2 web site (http://ggplot2.org)
- ggplot2 mailing list (http://goo.gl/OdW3uB), primarily for developers



```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# make this an external chunk that can be included in any file
options(width = 80)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/', fig.height = 4, cache = TRUE, fig.show = 'hold')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```

## What is ggplot2?

- An implementation of the __Grammar of Graphics__ by Leland Wilkinson
- Grammar of graphics represents and abstraction of graphics ideas/objects
- Think “verb”, “noun”, “adjective” for graphics
- Allows for a “theory” of graphics on which to build new graphics and graphics objects

---

## Basic Components of a ggplot2 Plot
- A _data frame_
- _aesthetic mappings_: how data are mapped to color, size 
- _geoms_: geometric objects like points, lines, shapes. 
- _facets_: for conditional plots. 
- _stats_: statistical transformations like binning, quantiles, smoothing. 
- _scales_: what scale an aesthetic map uses (example: male = red, female = blue). 
- _coordinate system_ 

---

## Building Plots with ggplot2
- When building plots in ggplot2 (rather than using qplot) the “artist’s palette” model may be the closest analogy
- Plots are built up in layers
  - Plot the data
  - Overlay a summary
  - Metadata and annotation

---

## Example: BMI, PM$_{2.5}$, Asthma
- Mouse Allergen and Asthma Cohort Study
- Baltimore children (age 5-17)
- Persistent asthma, exacerbation in past year
- Does BMI (normal vs. overweight) modify the relationship between PM$_{2.5}$ and asthma symptoms?

```{r,echo=FALSE}
maacs <- read.csv("ggplot2_lecture2_data.csv")
```

---

## Basic Plot

```{r, fig.width=9}
library(ggplot2)
qplot(logpm25, NocturnalSympt, data = maacs, facets = . ~ bmicat, 
      geom = c("point", "smooth"), method = "lm")
```

---

## Building Up in Layers

```{r}
head(maacs)
g <- ggplot(maacs, aes(logpm25, NocturnalSympt))
summary(g)
```


---

## No Plot Yet!

```{r, error=TRUE}
g <- ggplot(maacs, aes(logpm25, NocturnalSympt))
print(g)
```

---

## First Plot with Point Layer

```{r}
g <- ggplot(maacs, aes(logpm25, NocturnalSympt))
g + geom_point()
```

---

## Adding More Layers: Smooth

```{r, fig.width=4.5}
g + geom_point() + geom_smooth()
g + geom_point() + geom_smooth(method = "lm")
```

---

## Adding More Layers: Facets

```{r, fig.width=9}
g + geom_point() + facet_grid(. ~ bmicat) + geom_smooth(method = "lm")
```

---

## Annotation
- Labels: `xlab()`, `ylab()`, `labs()`, `ggtitle()`
- Each of the “geom” functions has options to modify 
- For things that only make sense globally, use `theme()` 
  - Example: `theme(legend.position = "none")` 
- Two standard appearance themes are included
  - `theme_gray()`: The default theme (gray background)
  - `theme_bw()`: More stark/plain 

---

## Modifying Aesthetics

```{r, fig.width=4.5}
g + geom_point(color = "steelblue", size = 4, alpha = 1/2)
g + geom_point(aes(color = bmicat), size = 4, alpha = 1/2)
```

---

## Modifying Labels

```{r}
g + geom_point(aes(color = bmicat)) + labs(title = "MAACS Cohort") + 
  labs(x = expression("log " * PM[2.5]), y = "Nocturnal Symptoms")
```

---

## Customizing the Smooth

```{r}
g + geom_point(aes(color = bmicat), size = 2, alpha = 1/2) + 
  geom_smooth(size = 4, linetype = 3, method = "lm", se = FALSE)
```

---

## Changing the Theme

```{r}
g + geom_point(aes(color = bmicat)) + theme_bw(base_family = "Times")
```

---

## A Note about Axis Limits

```{r, fig.width=4.5, fig.height=3}
testdat <- data.frame(x = 1:100, y = rnorm(100))
testdat[50,2] <- 100  ## Outlier!
plot(testdat$x, testdat$y, type = "l", ylim = c(-3,3))

g <- ggplot(testdat, aes(x = x, y = y))
g + geom_line()
```

---

## Axis Limits

```{r, fig.width=4.5}
g + geom_line() + ylim(-3, 3)
g + geom_line() + coord_cartesian(ylim = c(-3, 3))
```


---

## More Complex Example
- How does the relationship between PM$_{2.5}$ and nocturnal symptoms vary by BMI and NO$_2$?
- Unlike our previous BMI variable, NO$_2$ is continuous
- We need to make NO$_2$ categorical so we can condition on it in the plotting
- Use the `cut()` function for this

---

## Making NO$_2$ Tertiles

```{r}
## Calculate the tertiles of the data
cutpoints <- quantile(maacs$logno2_new, seq(0, 1, length = 4), na.rm = TRUE)

## Cut the data at the tertiles and create a new factor variable
maacs$no2tert <- cut(maacs$logno2_new, cutpoints)

## See the levels of the newly created factor variable
levels(maacs$no2tert)
```

---

## Final Plot

```{r, echo=FALSE, fig.width=9, fig.height=5}
## Setup ggplot with data frame
g <- ggplot(maacs, aes(logpm25, NocturnalSympt))

## Add layers
g + geom_point(alpha = 1/3) + 
  facet_wrap(bmicat ~ no2tert, nrow = 2, ncol = 4) + 
  geom_smooth(method="lm", se=FALSE, col="steelblue") + 
  theme_bw(base_family = "Avenir", base_size = 10) + 
  labs(x = expression("log " * PM[2.5])) + 
  labs(y = "Nocturnal Symptoms") + 
  labs(title = "MAACS Cohort")
```

---

## Code for Final Plot

```{r, eval=FALSE}
## Setup ggplot with data frame
g <- ggplot(maacs, aes(logpm25, NocturnalSympt))

## Add layers
g + geom_point(alpha = 1/3) + 
  facet_wrap(bmicat ~ no2tert, nrow = 2, ncol = 4) + 
  geom_smooth(method="lm", se=FALSE, col="steelblue") + 
  theme_bw(base_family = "Avenir", base_size = 10) + 
  labs(x = expression("log " * PM[2.5])) + 
  labs(y = "Nocturnal Symptoms") + 
  labs(title = "MAACS Cohort")
```

---

## Summary
- ggplot2 is very powerful and flexible if you learn the “grammar” and the various elements that can be tuned/modified
- Many more types of plots can be made; explore and mess around with the package (references mentioned in Part 1 are useful)




## Matrix data 



## Matrix data 

```{r randomData,fig.height=4,fig.width=3}
set.seed(12345); par(mar=rep(0.2,4))
dataMatrix <- matrix(rnorm(400),nrow=40)
image(1:10,1:40,t(dataMatrix)[,nrow(dataMatrix):1])
```

---

## Cluster the data 

```{r,fig.height=6,fig.width=6}
par(mar=rep(0.2,4))
heatmap(dataMatrix)
```

---

## What if we add a pattern?

```{r onePattern}
set.seed(678910)
for(i in 1:40){
  # flip a coin
  coinFlip <- rbinom(1,size=1,prob=0.5)
  # if coin is heads add a common pattern to that row
  if(coinFlip){
    dataMatrix[i,] <- dataMatrix[i,] + rep(c(0,3),each=5)
  }
}
```


---

## What if we add a pattern? - the data

```{r dependson ="onePattern",fig.height=5,fig.width=4}
par(mar=rep(0.2,4))
image(1:10,1:40,t(dataMatrix)[,nrow(dataMatrix):1])
```


---

## What if we add a pattern? - the clustered data

```{r dependson ="onePattern",fig.height=6,fig.width=6}
par(mar=rep(0.2,4))
heatmap(dataMatrix)
```



---

## Patterns in rows and columns



```{r oChunk, dependson ="onePattern",fig.height=4,fig.width=12}
hh <- hclust(dist(dataMatrix)); dataMatrixOrdered <- dataMatrix[hh$order,]
par(mfrow=c(1,3))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(rowMeans(dataMatrixOrdered),40:1,,xlab="Row Mean",ylab="Row",pch=19)
plot(colMeans(dataMatrixOrdered),xlab="Column",ylab="Column Mean",pch=19)
```

---

## Related problems

You have multivariate variables $X_1,\ldots,X_n$ so $X_1 = (X_{11},\ldots,X_{1m})$

* Find a new set of multivariate variables that are uncorrelated and explain as much variance as possible.
* If you put all the variables together in one matrix, find the best matrix created with fewer variables (lower rank) that explains the original data.


The first goal is <font color="#330066">statistical</font> and the second goal is <font color="#993300">data compression</font>.

---

## Related solutions - PCA/SVD

__SVD__

If $X$ is a matrix with each variable in a column and each observation in a row then the SVD is a "matrix decomposition"

$$ X = UDV^T$$

where the columns of $U$ are orthogonal (left singular vectors), the columns of $V$ are orthogonal (right singular vectors) and $D$ is a diagonal matrix (singular values). 

__PCA__

The principal components are equal to the right singular values if you first scale (subtract the mean, divide by the standard deviation) the variables.

---

## Components of the SVD - $u$ and $v$

```{r dependson ="oChunk",fig.height=4,fig.width=12}
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(svd1$u[,1],40:1,,xlab="Row",ylab="First left singular vector",pch=19)
plot(svd1$v[,1],xlab="Column",ylab="First right singular vector",pch=19)
```


---

## Components of the SVD - Variance explained

```{r dependson ="oChunk",fig.height=5,fig.width=10}
par(mfrow=c(1,2))
plot(svd1$d,xlab="Column",ylab="Singular value",pch=19)
plot(svd1$d^2/sum(svd1$d^2),xlab="Column",ylab="Prop. of variance explained",pch=19)
```


---

## Relationship to principal components

```{r dependson ="oChunk",fig.height=5,fig.width=5}
svd1 <- svd(scale(dataMatrixOrdered))
pca1 <- prcomp(dataMatrixOrdered,scale=TRUE)
plot(pca1$rotation[,1],svd1$v[,1],pch=19,xlab="Principal Component 1",ylab="Right Singular Vector 1")
abline(c(0,1))
```

---

## Components of the SVD - variance explained

```{r dependson ="oChunk",fig.height=4,fig.width=12,tidy=FALSE}
constantMatrix <- dataMatrixOrdered*0
for(i in 1:dim(dataMatrixOrdered)[1]){constantMatrix[i,] <- rep(c(0,1),each=5)}
svd1 <- svd(constantMatrix)
par(mfrow=c(1,3))
image(t(constantMatrix)[,nrow(constantMatrix):1])
plot(svd1$d,xlab="Column",ylab="Singular value",pch=19)
plot(svd1$d^2/sum(svd1$d^2),xlab="Column",ylab="Prop. of variance explained",pch=19)
```


---

## What if we add a second pattern?

```{r twoPattern, dependson ="randomData",fig.height=4,fig.width=3}
set.seed(678910)
for(i in 1:40){
  # flip a coin
  coinFlip1 <- rbinom(1,size=1,prob=0.5)
  coinFlip2 <- rbinom(1,size=1,prob=0.5)
  # if coin is heads add a common pattern to that row
  if(coinFlip1){
    dataMatrix[i,] <- dataMatrix[i,] + rep(c(0,5),each=5)
  }
  if(coinFlip2){
    dataMatrix[i,] <- dataMatrix[i,] + rep(c(0,5),5)
  }
}
hh <- hclust(dist(dataMatrix)); dataMatrixOrdered <- dataMatrix[hh$order,]
```

---

## Singular value decomposition - true patterns 

```{r  dependson ="twoPattern",fig.height=4.5,fig.width=12}
svd2 <- svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(rep(c(0,1),each=5),pch=19,xlab="Column",ylab="Pattern 1")
plot(rep(c(0,1),5),pch=19,xlab="Column",ylab="Pattern 2")
```

---

##  $v$ and patterns of variance in rows

```{r  dependson ="twoPattern",fig.height=4.5,fig.width=12}
svd2 <- svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(svd2$v[,1],pch=19,xlab="Column",ylab="First right singular vector")
plot(svd2$v[,2],pch=19,xlab="Column",ylab="Second right singular vector")
```


---

##  $d$ and variance explained

```{r dependson ="twoPattern",fig.height=4,fig.width=8}
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow=c(1,2))
plot(svd1$d,xlab="Column",ylab="Singular value",pch=19)
plot(svd1$d^2/sum(svd1$d^2),xlab="Column",ylab="Percent of variance explained",pch=19)
```

---

## Missing values

```{r,dependson="twoPattern",error=TRUE}
dataMatrix2 <- dataMatrixOrdered
## Randomly insert some missing data
dataMatrix2[sample(1:100,size=40,replace=FALSE)] <- NA
svd1 <- svd(scale(dataMatrix2))  ## Doesn't work!
```


---

## Imputing {impute}

```{r,dependson="twoPattern",fig.height=4,fig.width=8,tidy=FALSE}
library(impute)  ## Available from http://bioconductor.org
dataMatrix2 <- dataMatrixOrdered
dataMatrix2[sample(1:100,size=40,replace=FALSE)] <- NA
dataMatrix2 <- impute.knn(dataMatrix2)$data
svd1 <- svd(scale(dataMatrixOrdered)); svd2 <- svd(scale(dataMatrix2))
par(mfrow=c(1,2)); plot(svd1$v[,1],pch=19); plot(svd2$v[,1],pch=19)
```



---

## Face example

<!-- ## source("http://dl.dropbox.com/u/7710864/courseraPublic/myplclust.R") -->

```{r loadFaceData ,fig.height=6,fig.width=6}
load("data/face.rda")
image(t(faceData)[,nrow(faceData):1])
```


---

## Face example - variance explained

```{r,dependson="loadFaceData",fig.height=5,fig.width=6}
svd1 <- svd(scale(faceData))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singular vector",ylab="Variance explained")
```

---

## Face example - create approximations

```{r approximations,dependson="loadFaceData",fig.height=4,fig.width=4}

svd1 <- svd(scale(faceData))
## Note that %*% is matrix multiplication

# Here svd1$d[1] is a constant
approx1 <- svd1$u[,1] %*% t(svd1$v[,1]) * svd1$d[1]

# In these examples we need to make the diagonal matrix out of d
approx5 <- svd1$u[,1:5] %*% diag(svd1$d[1:5])%*% t(svd1$v[,1:5]) 
approx10 <- svd1$u[,1:10] %*% diag(svd1$d[1:10])%*% t(svd1$v[,1:10]) 
```

---

## Face example - plot approximations
```{r dependson="approximations",fig.height=4,fig.width=14}
par(mfrow=c(1,4))
image(t(approx1)[,nrow(approx1):1], main = "(a)")
image(t(approx5)[,nrow(approx5):1], main = "(b)")
image(t(approx10)[,nrow(approx10):1], main = "(c)")
image(t(faceData)[,nrow(faceData):1], main = "(d)")  ## Original data
```


---

## Notes and further resources

* Scale matters
* PC's/SV's may mix real patterns
* Can be computationally intensive
* [Advanced data analysis from an elementary point of view](http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV.pdf)
* [Elements of statistical learning](http://www-stat.stanford.edu/~tibs/ElemStatLearn/)
* Alternatives
  * [Factor analysis](http://en.wikipedia.org/wiki/Factor_analysis)
  * [Independent components analysis](http://en.wikipedia.org/wiki/Independent_component_analysis)
  * [Latent semantic analysis](http://en.wikipedia.org/wiki/Latent_semantic_analysis)






## Can we find things that are close together? 

Clustering organizes things that are __close__ into groups


* How do we define close?
* How do we group things?
* How do we visualize the grouping? 
* How do we interpret the grouping? 

---

## Hugely important/impactful

<img class=center src=../../assets/img/cluster.png height=450>

[http://scholar.google.com/scholar?hl=en&q=cluster+analysis&btnG=&as_sdt=1%2C21&as_sdtp=](http://scholar.google.com/scholar?hl=en&q=cluster+analysis&btnG=&as_sdt=1%2C21&as_sdtp=)

---

## Hierarchical clustering

* An agglomerative approach
  * Find closest two things
  * Put them together
  * Find next closest
* Requires
  * A defined distance
  * A merging approach
* Produces
  * A tree showing how close things are to each other


---


## How do we define close?

* Most important step
  * Garbage in -> garbage out
* Distance or similarity
  * Continuous - euclidean distance
  * Continuous - correlation similarity
  * Binary - manhattan distance
* Pick a distance/similarity that makes sense for your problem
  
  

---

## Example distances - Euclidean

<img class=center src=../../assets/img/distance.png height=450>

[http://rafalab.jhsph.edu/688/lec/lecture5-clustering.pdf](http://rafalab.jhsph.edu/688/lec/lecture5-clustering.pdf)


---

## Example distances - Euclidean

<img class=center src=../../assets/img/distance2.png height=300>

In general:

$$\sqrt{(A_1-A_2)^2 + (B_1-B_2)^2 + \ldots + (Z_1-Z_2)^2}$$
[http://rafalab.jhsph.edu/688/lec/lecture5-clustering.pdf](http://rafalab.jhsph.edu/688/lec/lecture5-clustering.pdf)



---

## Example distances - Manhattan

<img class=center src=../../assets/img/manhattan.svg height=300>

In general:

$$|A_1-A_2| + |B_1-B_2| + \ldots + |Z_1-Z_2|$$

[http://en.wikipedia.org/wiki/Taxicab_geometry](http://en.wikipedia.org/wiki/Taxicab_geometry)



---

## Hierarchical clustering - example

```{r createData, fig.height=3.5,fig.width=3.5}
set.seed(1234); par(mar=c(0,0,0,0))
x <- rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y <- rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
```


---

## Hierarchical clustering - `dist`

* Important parameters: _x_,_method_
```{r dependson="createData",fig.height=4,fig.width=4}
dataFrame <- data.frame(x=x,y=y)
dist(dataFrame)
```

---

## Hierarchical clustering - #1

```{r dependson="createData",echo=FALSE, fig.height=4,fig.width=8}
suppressMessages(library(fields))
dataFrame <- data.frame(x=x,y=y)
rdistxy <- rdist(dataFrame)
diag(rdistxy) <- diag(rdistxy) + 1e5

# Find the index of the points with minimum distance
ind <- which(rdistxy == min(rdistxy),arr.ind=TRUE)
par(mfrow=c(1,2),mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=2)

# Make a cluster and cut it at the right height
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[1]+0.00001) )
plot(cutDendro$lower[[11]],yaxt="n")
```



---

## Hierarchical clustering - #2

```{r dependson="createData",echo=FALSE}
library(fields)
dataFrame <- data.frame(x=x,y=y)
rdistxy <- rdist(dataFrame)
diag(rdistxy) <- diag(rdistxy) + 1e5

# Find the index of the points with minimum distance
ind <- which(rdistxy == min(rdistxy),arr.ind=TRUE)
par(mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=2)
points(mean(x[ind[1,]]),mean(y[ind[1,]]),col="black",cex=3,lwd=3,pch=3)
points(mean(x[ind[1,]]),mean(y[ind[1,]]),col="orange",cex=5,lwd=3,pch=1)


```



---

## Hierarchical clustering - #3

```{r dependson="createData",echo=FALSE, fig.height=5,fig.width=14}
library(fields)
dataFrame <- data.frame(x=x,y=y)
rdistxy <- rdist(dataFrame)
diag(rdistxy) <- diag(rdistxy) + 1e5

# Find the index of the points with minimum distance
ind <- which(rdistxy == rdistxy[order(rdistxy)][3],arr.ind=TRUE)
par(mfrow=c(1,3),mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
points(x[c(5,6)],y[c(5,6)],col="orange",pch=19,cex=2)
points(x[ind[1,]],y[ind[1,]],col="red",pch=19,cex=2)

# Make dendogram plots
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[2]) )
plot(cutDendro$lower[[10]],yaxt="n")
plot(cutDendro$lower[[5]],yaxt="n")

```



---

## Hierarchical clustering - hclust

```{r, dependson="createData", fig.height=4,fig.width=4}
dataFrame <- data.frame(x=x,y=y)
distxy <- dist(dataFrame)
hClustering <- hclust(distxy)
plot(hClustering)
```


---

## Prettier dendrograms

```{r plclust}
myplclust <- function( hclust, lab=hclust$labels, lab.col=rep(1,length(hclust$labels)), hang=0.1,...){
  ## modifiction of plclust for plotting hclust objects *in colour*!
  ## Copyright Eva KF Chan 2009
  ## Arguments:
  ##    hclust:    hclust object
  ##    lab:        a character vector of labels of the leaves of the tree
  ##    lab.col:    colour for the labels; NA=default device foreground colour
  ##    hang:     as in hclust & plclust
  ## Side effect:
  ##    A display of hierarchical cluster with coloured leaf labels.
  y <- rep(hclust$height,2); x <- as.numeric(hclust$merge)
  y <- y[which(x<0)]; x <- x[which(x<0)]; x <- abs(x)
  y <- y[order(x)]; x <- x[order(x)]
  plot( hclust, labels=FALSE, hang=hang, ... )
  text( x=x, y=y[hclust$order]-(max(hclust$height)*hang),
        labels=lab[hclust$order], col=lab.col[hclust$order], 
        srt=90, adj=c(1,0.5), xpd=NA, ... )
}

```


---

## Pretty dendrograms

```{r, dependson="createData", fig.height=4,fig.width=4}
dataFrame <- data.frame(x=x,y=y)
distxy <- dist(dataFrame)
hClustering <- hclust(distxy)
myplclust(hClustering,lab=rep(1:3,each=4),lab.col=rep(1:3,each=4))
```

---

## Even Prettier dendrograms


<img class=center src=../../assets/img/prettydendro.png height=450>


[http://gallery.r-enthusiasts.com/RGraphGallery.php?graph=79](http://gallery.r-enthusiasts.com/RGraphGallery.php?graph=79)


---

## Merging points - complete

```{r,echo=FALSE,dependson="createData"}
dataFrame <- data.frame(x=x,y=y)
par(mar=rep(0.1,4))
plot(x,y,col="blue",pch=19,cex=2)
points(x[8],y[8],col="orange",pch=3,lwd=3,cex=3)
points(x[1],y[1],col="orange",pch=3,lwd=3,cex=3)
segments(x[8],y[8],x[1],y[1],lwd=3,col="orange")

```



---

## Merging points - average

```{r,echo=FALSE,dependson="createData"}
dataFrame <- data.frame(x=x,y=y)
par(mar=rep(0.1,4))
plot(x,y,col="blue",pch=19,cex=2)
points(mean(x[1:4]),mean(y[1:4]),col="orange",pch=3,lwd=3,cex=3)
points(mean(x[5:8]),mean(y[5:8]),col="orange",pch=3,lwd=3,cex=3)
segments(mean(x[1:4]),mean(y[1:4]),mean(x[5:8]),mean(y[5:8]),lwd=3,col="orange")

```


---

## `heatmap()`

```{r,dependson="createData",fig.height=5,fig.width=6}
dataFrame <- data.frame(x=x,y=y)
set.seed(143)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
heatmap(dataMatrix)
```



---

## Notes and further resources

* Gives an idea of the relationships between variables/observations
* The picture may be unstable
  * Change a few points
  * Have different missing values
  * Pick a different distance
  * Change the merging strategy
  * Change the scale of points for one variable
* But it is deterministic
* Choosing where to cut isn't always obvious
* Should be primarily used for exploration 
* [Rafa's Distances and Clustering Video](http://www.youtube.com/watch?v=wQhVWUcXM0A)
* [Elements of statistical learning](http://www-stat.stanford.edu/~tibs/ElemStatLearn/)




## Can we find things that are close together? 

* How do we define close?
* How do we group things?
* How do we visualize the grouping? 
* How do we interpret the grouping? 


---

## How do we define close?

* Most important step
  * Garbage in $\longrightarrow$ garbage out
* Distance or similarity
  * Continuous - euclidean distance
  * Continous - correlation similarity
  * Binary - manhattan distance
* Pick a distance/similarity that makes sense for your problem
  

---

## K-means clustering

* A partioning approach
  * Fix a number of clusters
  * Get "centroids" of each cluster
  * Assign things to closest centroid
  * Reclaculate centroids
* Requires
  * A defined distance metric
  * A number of clusters
  * An initial guess as to cluster centroids
* Produces
  * Final estimate of cluster centroids
  * An assignment of each point to clusters
  

---

## K-means clustering -  example


```{r createData, fig.height=3.5,fig.width=3.5}
set.seed(1234); par(mar=c(0,0,0,0))
x <- rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y <- rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
```


---

## K-means clustering -  starting centroids


```{r,dependson="createData",echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
cx <- c(1,1.8,2.5)
cy <- c(2,1,1.5)
points(cx,cy,col=c("red","orange","purple"),pch=3,cex=2,lwd=2)
```

---

## K-means clustering -  assign to closest centroid

```{r,dependson="createData",echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=as.character(1:12))
cx <- c(1,1.8,2.5)
cy <- c(2,1,1.5)
points(cx,cy,col=cols1,pch=3,cex=2,lwd=2)

## Find the closest centroid
distTmp <- matrix(NA,nrow=3,ncol=12)
distTmp[1,] <- (x-cx[1])^2 + (y-cy[1])^2
distTmp[2,] <- (x-cx[2])^2 + (y-cy[2])^2
distTmp[3,] <- (x-cx[3])^2 + (y-cy[3])^2
newClust <- apply(distTmp,2,which.min)
points(x,y,pch=19,cex=2,col=cols1[newClust])
```

---

## K-means clustering -  recalculate centroids

```{r,dependson="createData",echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=as.character(1:12))

## Find the closest centroid
distTmp <- matrix(NA,nrow=3,ncol=12)
distTmp[1,] <- (x-cx[1])^2 + (y-cy[1])^2
distTmp[2,] <- (x-cx[2])^2 + (y-cy[2])^2
distTmp[3,] <- (x-cx[3])^2 + (y-cy[3])^2
newClust <- apply(distTmp,2,which.min)
points(x,y,pch=19,cex=2,col=cols1[newClust])
newCx <- tapply(x,newClust,mean)
newCy <- tapply(y,newClust,mean)

## Old centroids

cx <- c(1,1.8,2.5)
cy <- c(2,1,1.5)

points(newCx,newCy,col=cols1,pch=3,cex=2,lwd=2)

```


---

## K-means clustering -  reassign values

```{r,dependson="createData",echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=as.character(1:12))


cx <- c(1,1.8,2.5)
cy <- c(2,1,1.5)


## Find the closest centroid
distTmp <- matrix(NA,nrow=3,ncol=12)
distTmp[1,] <- (x-cx[1])^2 + (y-cy[1])^2
distTmp[2,] <- (x-cx[2])^2 + (y-cy[2])^2
distTmp[3,] <- (x-cx[3])^2 + (y-cy[3])^2
newClust <- apply(distTmp,2,which.min)
newCx <- tapply(x,newClust,mean)
newCy <- tapply(y,newClust,mean)

## Old centroids

points(newCx,newCy,col=cols1,pch=3,cex=2,lwd=2)


## Iteration 2
distTmp <- matrix(NA,nrow=3,ncol=12)
distTmp[1,] <- (x-newCx[1])^2 + (y-newCy[1])^2
distTmp[2,] <- (x-newCx[2])^2 + (y-newCy[2])^2
distTmp[3,] <- (x-newCx[3])^2 + (y-newCy[3])^2
newClust2 <- apply(distTmp,2,which.min)

points(x,y,pch=19,cex=2,col=cols1[newClust2])

```



---

## K-means clustering -  update centroids

```{r,dependson="createData",echo=FALSE,fig.height=5,fig.width=5}
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=as.character(1:12))


cx <- c(1,1.8,2.5)
cy <- c(2,1,1.5)

## Find the closest centroid
distTmp <- matrix(NA,nrow=3,ncol=12)
distTmp[1,] <- (x-cx[1])^2 + (y-cy[1])^2
distTmp[2,] <- (x-cx[2])^2 + (y-cy[2])^2
distTmp[3,] <- (x-cx[3])^2 + (y-cy[3])^2
newClust <- apply(distTmp,2,which.min)
newCx <- tapply(x,newClust,mean)
newCy <- tapply(y,newClust,mean)



## Iteration 2
distTmp <- matrix(NA,nrow=3,ncol=12)
distTmp[1,] <- (x-newCx[1])^2 + (y-newCy[1])^2
distTmp[2,] <- (x-newCx[2])^2 + (y-newCy[2])^2
distTmp[3,] <- (x-newCx[3])^2 + (y-newCy[3])^2
finalClust <- apply(distTmp,2,which.min)


## Final centroids
finalCx <- tapply(x,finalClust,mean)
finalCy <- tapply(y,finalClust,mean)
points(finalCx,finalCy,col=cols1,pch=3,cex=2,lwd=2)



points(x,y,pch=19,cex=2,col=cols1[finalClust])

```


---

## `kmeans()`

* Important parameters: _x_, _centers_, _iter.max_, _nstart_

```{r kmeans,dependson="createData"}
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=3)
names(kmeansObj)
kmeansObj$cluster
```

---

## `kmeans()`

```{r, dependson="kmeans",fig.height=4,fig.width=4}
par(mar=rep(0.2,4))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
```

---

## Heatmaps

```{r, dependson="kmeans",fig.height=4,fig.width=8}
set.seed(1234)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
kmeansObj <- kmeans(dataMatrix,centers=3)
par(mfrow=c(1,2), mar = c(2, 4, 0.1, 0.1))
image(t(dataMatrix)[,nrow(dataMatrix):1],yaxt="n")
image(t(dataMatrix)[,order(kmeansObj$cluster)],yaxt="n")
```



---

## Notes and further resources

* K-means requires a number of clusters
  * Pick by eye/intuition
  * Pick by cross validation/information theory, etc.
  * [Determining the number of clusters](http://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)
* K-means is not deterministic
  * Different # of clusters 
  * Different number of iterations
* [Rafael Irizarry's Distances and Clustering Video](http://www.youtube.com/watch?v=wQhVWUcXM0A)
* [Elements of statistical learning](http://www-stat.stanford.edu/~tibs/ElemStatLearn/)







