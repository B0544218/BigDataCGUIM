---
title: "資料探勘"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 問題

用`BostonHousing`資料
`install.packages(“mlbench”)`
`library(mlbench)`
`data(BostonHousing)`
使用`crim`、`tax`、`dis`欄位預測`medv`(Median value of owner-occupied homes in $1000's)
`glm()`廣義線性迴歸

### 解答

```{r }
library(mlbench)
data(BostonHousing)

model1<-glm(formula = medv~crim+tax+dis,
   data = BostonHousing)
model1
```

- 模型方程式為medv = 31.86107 - 0.18855 x crim - 0.02047 x tax - 0.07644 x dis
- 模型AIC值為3352
- 由此方程式的係數可知`medv`的值會與`crim`, `tax`, `dis`等三個變數成反比

<hr>

### 問題

用`BostonHousing`資料
`install.packages(“mlbench”)`
`library(mlbench)`
`data(BostonHousing)`
使用`crim`、`tax`、`dis`、`RM`、 `AGE`、 `CHAS`欄位預測`medv`(Median value of owner-occupied homes in $1000‘s)，請問跟上一題比較，所有參數都有用嗎? 哪一個模型配適度較高?
`glm()`廣義線性迴歸

### 解答

```{r }
library(mlbench)
model2<-glm(medv~crim+tax+dis+rm+age+chas,data=BostonHousing)

model1$aic
model2$aic
```

- 由於model2的AIC較model1的AIC小，可看出model2的模型配適度較佳

```{r }
summary(model2)
```

- 由model2中的p-value可知，所有變數在模型中均可合理存在(p-value<0.05)

```{r}
model2$coefficients
```

- model2的模型方程式為medv = -11.43069301 - 0.13321893 x crim - 0.01110297 x tax - 0.88334600 x dis + 7.58809421 x rm - 0.08215356 x age + 3.97781599 x chas1
- 由此方程式可知medv的值會與`crim`, `tax`, `dis`, `age` 等四個變數成反比，與`rm`, `chas1`成正比

<hr>

### 問題

運用決策樹演算法，以iris資料中所有欄位預測物種
`Species~.`
最後使用`rpart.plot`套件畫出決策樹
`prp()`

### 解答

** `~`左邊放要預測的變數，右邊放用來預測的變數，`~.`的用法表示以所有欄位進行預測 **

```{r }
library(rpart)
library(rpart.plot)
irisTree <- rpart(Species~.,data = iris)
prp(irisTree)
```

此決策樹共有兩個節點(Petal.Length<2.5及Petal.Width<1.8)，可以這些特徵進行物種的分類

<hr>

### 問題

用`BostonHousing`資料
`install.packages(“mlbench”)
library(mlbench)
data(BostonHousing)`
使用全部的欄位預測`medv(Median value of owner-occupied homes in $1000‘s)`，並用雙向逐步回歸法尋找最佳參數組合，請問最後選出的參數是?
`glm()`廣義線性迴歸
`stepAIC()`逐步回歸，記得選雙向

### 解答

```{r }
library(mlbench)
library(MASS)
data(BostonHousing)
BostonHousingData<-
 glm(medv~.,
     data=BostonHousing)
BostonHousingModel<-
 stepAIC(BostonHousingData,
         direction="both",
         trace=T)
summary(BostonHousingModel)$coefficients
```

<hr>

### 問題

用BostonHousing資料install.packages(“mlbench”)library(mlbench)data(BostonHousing)分析前先將資料的1/3切成測試組，2/3切成訓練組，使用訓練組全部的欄位預測medv(Median value of owner-occupied homes in $1000‘s)，並用雙向逐步回歸法尋找最佳參數組合，請問最後選出的參數是?glm()廣義線性迴歸stepAIC()逐步回歸，記得選雙向

### 解答

```{r }
library(mlbench)
library(MASS)

data(BostonHousing)
BostonHousing$Test<-F 

BostonHousing[sample(1:nrow(BostonHousing),
                    nrow(BostonHousing)/3),]$Test<-T

DT<-glm( medv~. ,
        data =BostonHousing[BostonHousing$Test==F,])

BostonHousingModel2<-
 stepAIC(DT,
         direction = "both")
summary(BostonHousingModel2)$coefficients
```

<hr>

### 問題

用BostonHousing資料
install.packages(“mlbench”)
library(mlbench)
data(BostonHousing)
分析前先將資料的1/3切成測試組，2/3切成訓練組，使用訓練組全部的欄位預測medv(Median value of owner-occupied homes in $1000‘s)，並用雙向逐步回歸法尋找最佳參數組合與模型，並使用測試組做驗證，測試組的預測房價與真實房價的相關係數是?
Glm()廣義線性迴歸
stepAIC()逐步回歸，記得選雙向
cor()

### 解答

```{r }

predictPoint<-
 predict(DT, #Test==T, test data
         newdata = BostonHousing[BostonHousing$Test==T,])

cor(x=predictPoint,
   y=BostonHousing[BostonHousing$Test==T,]$medv)

```

<hr>

### 問題

用BostonHousing資料
install.packages(“mlbench”)
library(mlbench)
data(BostonHousing)
分析前先將資料的1/3切成測試組，2/3切成訓練組，使用訓練組全部的欄位預測medv(Median value of owner-occupied homes in $1000‘s)，並用雙向逐步回歸法尋找最佳參數組合與模型，並使用測試組做驗證，請用測試組的預測房價與真實房價畫散佈圖，並加上回歸線
Glm()廣義線性迴歸
stepAIC()逐步回歸，記得選雙向
ggplot() + geom_point()

### 解答

```{r }
library(ggplot2)
compareTable<-data.frame(real=predictPoint,predict =  
                           BostonHousing[BostonHousing$Test==T,]$medv)

ggplot(compareTable,aes(x=real, y=predict))+
  geom_point()+
  geom_smooth(method = 'lm')
```

<hr>

### 問題

Sonar資料記載礦物與石頭接受各個不同角度的聲波撞擊後，接收到的回聲數值
一共有60個參數，代表使用一特別角度的聲波撞擊礦石所得回聲，
分類結果為二元分類，包括礦物 (M) 與石頭 (R) ，
將資料隨機分為訓練組(2/3)與測試組(1/3)，
使用決策樹演算法訓練模型並驗證，使用測試組資料計算正確率(猜對/全部)。
library(mlbench)
data(Sonar)

### 解答
```{r }
library(mlbench)
data(Sonar)
#分測試組及訓練組
Sonar$Test<-F
Sonar[sample(1:nrow(Sonar),nrow(Sonar)/3),]$Test<-T

#做決策樹
DT<-rpart(Class~.,data=Sonar[Sonar$Test==F,])
#做預測
ClassPredicted<-predict(DT,newdata=Sonar[Sonar$Test==T,],type="class")
#比對預測結果與實際結果，並計算正確率
SonarResult<-data.frame(predict=ClassPredicted,real=Sonar[Sonar$Test==T,]$Class)
correctRate<-nrow(SonarResult[SonarResult$predict==SonarResult$real,])/nrow(SonarResult)
correctRate
```
<hr>