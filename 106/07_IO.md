資料讀取與匯出
========================================================
author: 曾意儒 Yi-Ju Tseng
autosize: true
font-family: 'Microsoft JhengHei'
navigation: slide

對應書本章節
========================================================
[5 資料讀取與匯出](http://yijutseng.github.io/DataScienceRBook/io.html)

大綱
====================================
- 從檔案匯入
- 從網路匯入
- 從Facebook匯入
- 資料匯出

資料分析步驟
====================================
- **資料匯入** <-----本章！
- **資料清洗處理**並轉換為Tidy data
- **資料分析**
- **資料呈現與視覺化**

從檔案匯入
====================================
type:section
- Import Dataset功能 (RStudio)
- 分隔文字檔 .txt
- CSV檔案 .csv
- Excel檔案 .xls
- R物件 .rds
- R程式 .R
- 純文字資料 (無分隔)
- 其他格式

Import Dataset功能 (RStudio)
====================================
選取RStudio四分割視窗右上角的Environment標籤，選擇**Import Dataset**

![plot of chunk unnamed-chunk-1](figures/import.png)

Import Dataset功能 (RStudio)
====================================
- 選取`From CSV`
- 點選`Browse`按鈕開啟檔案選取器

![plot of chunk unnamed-chunk-2](figures/csv.png)

Import Dataset功能 (RStudio)
====================================
- 利用下方`Import Options`的選項微調參數
    - `Delimiter`分隔符號
    - `First Row as Names`首列是否為欄位名稱
    
![plot of chunk unnamed-chunk-3](figures/csv2.png)

Import Dataset功能 (RStudio)
====================================
type:alert
incremental:true

- 操作[範例檔案](https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/104/POLIO_Incidence.csv)
- 若匯入的檔案為**tab分隔文字檔**? 該如何調整參數？

分隔文字檔 .txt
====================================
type:sub-section

- `readr` package提供完整的文字檔讀取功能
- 各讀取函數的第一個參數通常為**檔案路徑與名稱**
- `read_delim()`函數：用分隔符號分隔的文字檔案
    - `delim`=`\t`，tab分隔檔案
    - `col_names`：TRUE代表資料內有包含欄位名稱(首列)
        - 如果為FALSE，欄位名稱則會被設定為 X1, X2, X3 ...
    
TAB分隔文字檔 .txt
====================================

```r
library(readr) 
#第一次使用前需要安裝 install.packages("readr")
dataset <- read_delim("檔案路徑與名稱", delim="\t")
```

CSV檔案 .csv
====================================
type:sub-section
- `readr` package
- `read_csv()`

```r
library(readr)
#第一次使用前需要安裝 install.packages("readr")
dataset <- read_csv("檔案路徑與名稱")
```


Excel檔案 .xls
====================================
type:sub-section
- `readxl` package
- `read_excel()`函數
    - `col_names`參數
    - `sheet`參數設定要讀取的工作表(sheet)

```r
library(readxl)
#第一次使用前需要安裝 install.packages("readxl")
dataset <- read_excel("檔案路徑與名稱")
```

檔案匯入練習
====================================
type:alert
incremental:true

- 下載[範例CSV檔案](https://raw.githubusercontent.com/yijutseng/BigDataCGUIM/master/files/opendata10401.csv)，並在RStudio匯入
    - 方法一
    - 方法二
- 匯入後，**檢查**匯入的資料，資料內有幾筆觀察值？每筆觀察值中有幾個欄位？

R物件 .rds
====================================
type:sub-section
如果在R程式內處理完資料後，必須儲存一份資料以供後續分析，使用**R物件**儲存是最佳的方式

- 檔案小
- 讀取快速
- 推薦使用`readRDS()`函數讀取RDS檔案
- [A better way of saving and loading objects in R](http://www.fromthebottomoftheheap.net/2012/04/01/saving-and-loading-r-objects/)

```r
dataset <- readRDS("檔案路徑與名稱")
```

R程式 .R
====================================
type:sub-section
- `source`函數
- 讀R的Obejct or script, 並**執行**
- **實際操作範例**
    - 有一份example.R檔在工作環境中
    - 一次執行檔案內所有R指令

```r
source("example.R") 
```

純文字資料 (無分隔)
====================================
type:sub-section
`readLines`, 逐行讀取文字資料

其他格式 (透過載入套件)
====================================
type:sub-section

- MySQL `RMySQL`
- Weka `foreign`
- Stata `foreign`
- SPSS `Hmisc`
- SAS `Hmisc`
- GIS `rgdal`
- Images `jpeg`
- Music `tuneR`


其他讀檔注意事項
====================================
type:sub-section

讀檔的時候R會自動:

- 判斷要讀幾行
- 判斷每個列（Column）的類別
- 把欄位包起來的符號

如果讀取時已指定**Column類別**以及**把欄位包起來的符號**，讀取速度會快很多。

從網路匯入
====================================
type:section

- Open Data
- XML 可延伸標記式語言
- 網頁爬蟲 Webscraping
- API (Application programming interfaces)
- JSON格式檔案



Open Data 開放資料
====================================
type:sub-section
- 2011年推動開放政府與開放資料 ([維基百科](https://zh.wikipedia.org/wiki/%E9%96%8B%E6%94%BE%E8%B3%87%E6%96%99))
- 不受著作權、專利權，以及其他管理機制所限制，任何人都可以自由出版使用
- 常見的儲存方式為: 
    - `CSV`
    - `JSON`
    - `XML`
    
Open Data 開放資料常見平台
====================================
- [政府資料開放平台](http://data.gov.tw/)
- [Data Taipei](http://data.taipei/)
- [開放資料 x 開放桃園](http://data.tycg.gov.tw/)
- [內政資料開放平台](http://data.moi.gov.tw/)

API
====================================
type:sub-section
- 應用程式介面
- **A**pplication **P**rogramming **I**nterfaces
- 為了讓第三方的開發者可以額外開發應用程式來強化他們的產品，推出可以與系統溝通的介面
- 有API輔助可將資料擷取過程自動化
    -  以下載Open Data為例，若檔案更新頻繁，使用手動下載相當耗時
- [維基百科](https://zh.wikipedia.org/zh-tw/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%8E%A5%E5%8F%A3)

XML 可延伸標記式語言
====================================
type:sub-section

- E**x**tensible **m**arkup **l**anguage
- 描述**結構化**資料的語言
- 處理XML檔案是網頁**Html**爬蟲的基礎
- Components
    - Markup 標記 - labels that give the text structure
    - Content 內文 - the actual text of the document
- [XML Wiki](https://zh.wikipedia.org/wiki/XML)

XML 可延伸標記式語言
====================================
Tags, elements and attributes

- Tags correspond to general labels
    - Start tags `<breakfast_menu>`, `<price>`
    - End tags `</breakfast_menu>`,`</price>`
    - Empty tags `<line-break />`
- Elements are specific examples of tags
    - `<name>Belgian Waffles</name>`
- Attributes are components of the label
    - `<book category="web">`
    
XML 可延伸標記式語言-讀取
====================================
- [臺北市水質監測資訊](http://data.taipei/opendata/datalist/datasetMeta/download?id=961ca397-4a59-45e8-b312-697f26b059dc&rid=190796c8-7c56-42e0-8068-39242b8ec927)
- 安裝`XML` package（只需安裝一次）
- 載入`XML` package
- `xmlParse()`函數將XML檔案匯入


```r
library(XML)
waterURL<-"http://data.taipei/opendata/datalist/datasetMeta/download?id=961ca397-4a59-45e8-b312-697f26b059dc&rid=190796c8-7c56-42e0-8068-39242b8ec927"
waterQ <- xmlParse(waterURL)
```


XPath?
====================================
- XML路徑語言（XML Path Language）
- 基於XML的樹狀結構，提供在資料結構樹中找尋節點的能力
- [維基百科](https://zh.wikipedia.org/wiki/XPath)
- [中文教學](http://tech-marsw.logdown.com/blog/2016/01/11/parsing-lxml-xpath-sheet)
- [W3C教學](https://www.w3schools.com/xml/xpath_syntax.asp)


列舉XPath常用的語法
====================================
```
// : 子結點資料
```
如所有連結標籤 //a

```
@ : 屬性資料
```
如所有連結標籤內的連結網址 //a/@href

XML 可延伸標記式語言-解析
====================================
使用`xpathSApply()`函數取得指定標籤內的資料

```r
#取得所有"code_name"標籤內的資料
xpathSApply(waterQ,"//code_name",xmlValue)[1:10]
```

```
 [1] "雙溪淨水場"               "衛理女中"                
 [3] "雙溪國小                " "華興加壓站"              
 [5] "長興淨水場"               "市政大樓"                
 [7] "市議會"                   "捷運忠孝復興站"          
 [9] "南港高工"                 "南港加壓站"              
```

XML 可延伸標記式語言-解析
====================================
使用`xpathSApply()`函數取得指定標籤內的資料

```r
#取得各監測站的經度
xpathSApply(waterQ,"//longitude",xmlValue)[1:10]
```

```
 [1] "121.56094" "121.54401" "121.55557" "121.53476" "121.54043"
 [6] "121.55661" "121.55360" "121.53551" "121.59892" "121.60829"
```

xpathSApply vs. xpathApply
====================================
- xpathSApply: 回傳的物件是Vector 向量
- xpathApply: 回傳的物件是List 列表
- 延伸閱讀: [apply家族介紹](http://blog.bryanbigdata.com/2014/06/r-applysapplylapply.html)

XML檔案匯入練習
====================================
type:alert
incremental:true
- 載入[桃園捷運車站出入口基本資料](http://data.tycg.gov.tw/opendata/datalist/datasetMeta/download?id=b2653545-9425-46df-9a50-74ade59ab0cf&rid=f6362ce8-719b-4752-bec6-7fd995b623fd)
- 嘗試取得各站出入口敘述(LocationDescription)與經緯度(PositionLon,PositionLat)
- 參考剛剛的水站範例

```r
library(XML)
waterURL<-"http://data.taipei/opendata/datalist/datasetMeta/download?id=961ca397-4a59-45e8-b312-697f26b059dc&rid=190796c8-7c56-42e0-8068-39242b8ec927"
waterQ <- xmlParse(waterURL)
xpathSApply(waterQ,"//longitude",xmlValue)[1:10]
```


JSON格式檔案
====================================
type:sub-section

- JSON (**J**ava**s**cript **O**bject **N**otation)
- 輕量級的資料交換語言
- From **a**pplication **p**rogramming **i**nterfaces (APIs)
- JavaScript、Java、Node.js應用
- 一些NoSQL資料庫用JSON儲存資料：**MongoDB**
- [Wiki](http://en.wikipedia.org/wiki/JSON)

JSON資料儲存格式
====================================
- Numbers (double)
- Strings (double quoted)
- Boolean (_true_ or _false_)
- Array (ordered, comma separated enclosed in square brackets _[]_)
- Object (unorderd, comma separated collection of **key:value** pairs in curley brackets _{}_)

[JSON檔案範例](https://api.github.com/users/yijutseng/repos)


API
====================================
type:sub-section
- 應用程式介面
- **A**pplication **P**rogramming **I**nterfaces
- 為了讓第三方的開發者可以額外開發應用程式來強化他們的產品，推出可以與系統溝通的介面
- 有API輔助可將資料擷取過程自動化
    -  以下載Open Data為例，若檔案更新頻繁，使用手動下載相當耗時
- [維基百科](https://zh.wikipedia.org/zh-tw/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%8E%A5%E5%8F%A3)

API - Open Data
====================================
- [桃園公共自行車即時服務資料](http://data.tycg.gov.tw/opendata/datalist/datasetMeta?oid=5ca2bfc7-9ace-4719-88ae-4034b9a5a55c)資料
- 即時更新
- 不可能手動下載
- 提供透過**API**下載的服務
- 透過API下載的資料格式: **JSON格式**

***

- [桃園公共自行車即時服務資料API資訊](http://data.tycg.gov.tw/opendata/datalist/datasetMeta/outboundDesc?id=5ca2bfc7-9ace-4719-88ae-4034b9a5a55c&rid=a1b4714b-3b75-4ff8-a8f2-cc377e4eaa0f)
    - **資料集ID**: 紀錄資料的基本參數，如包含欄位、更新頻率等
    - **資料RID**: 資料集



JSON檔案匯入
====================================
- `jsonlite` package (套件使用前必須安裝)
- `fromJSON()`函數載入JSON資料
- 如果API網址為**https**，則需使用 `httr` package
    - 使用`GET()`函數處理資料擷取網址
- API網址參考[桃園公共自行車即時服務資料API資訊](http://data.tycg.gov.tw/opendata/datalist/datasetMeta/outboundDesc?id=5ca2bfc7-9ace-4719-88ae-4034b9a5a55c&rid=a1b4714b-3b75-4ff8-a8f2-cc377e4eaa0f)

```r
library(jsonlite)
library(RCurl)
APIData<-fromJSON("http://data.tycg.gov.tw/api/v1/rest/datastore/a1b4714b-3b75-4ff8-a8f2-cc377e4eaa0f?format=json")
```

JSON檔案匯入
====================================
- 轉存為`列表list`的型態
- 兩個子元素(success, result)
- result中records子元素的類別為資料框data.frame

```r
str(APIData)
```

```
List of 2
 $ success: logi TRUE
 $ result :List of 5
  ..$ resource_id: chr "a1b4714b-3b75-4ff8-a8f2-cc377e4eaa0f"
  ..$ fields     :'data.frame':	15 obs. of  2 variables:
  .. ..$ type: chr [1:15] "int4" "text" "text" "text" ...
  .. ..$ id  : chr [1:15] "_id" "sno" "sna" "tot" ...
  ..$ records    :'data.frame':	100 obs. of  15 variables:
  .. ..$ _id    : int [1:100] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ sarea  : chr [1:100] "中壢區" "中壢區" "中壢區" "中壢區" ...
  .. ..$ sareaen: chr [1:100] "Zhongli Dist." "Zhongli Dist." "Zhongli Dist." "Zhongli Dist." ...
  .. ..$ sna    : chr [1:100] "中央大學圖書館" "中壢高中" "中正公園(中美路)" "中壢火車站(前站)" ...
  .. ..$ aren   : chr [1:100] "No.300, Zhongda Rd." "No.215, Sec. 2, Zhongyang W. Rd. (opposite)" "No.101 to No.113, Zhongmei Rd. (opposite)" "No.139, Zhonghe Rd. (opposite)" ...
  .. ..$ sno    : chr [1:100] "2001" "2002" "2003" "2004" ...
  .. ..$ tot    : chr [1:100] "60" "52" "54" "98" ...
  .. ..$ snaen  : chr [1:100] "National Central University Library" "Jhungli Senior High School" "Zhongzheng Park" "TRA Zhongli Station (Front)" ...
  .. ..$ bemp   : chr [1:100] "0" "0" "-2" "0" ...
  .. ..$ ar     : chr [1:100] "中大路300號(中央大學校內圖書館前)" "中央西路二段215號對面人行道" "中美路101號-113號對面人行道" "中和路139號對面圓環" ...
  .. ..$ act    : chr [1:100] "0" "0" "0" "0" ...
  .. ..$ lat    : chr [1:100] "24.968128" "24.960815" "24.959113" "24.953874" ...
  .. ..$ lng    : chr [1:100] "121.194666" "121.212038" "121.224805" "121.2256" ...
  .. ..$ sbi    : chr [1:100] "0" "0" "0" "0" ...
  .. ..$ mday   : chr [1:100] "20180401001924" "20180401001929" "20180401001934" "20180401001938" ...
  ..$ total      : int 186
  ..$ limit      : int 100
```

JSON檔案解析
====================================
- 使用`$`符號截取元素與子元素

```r
head(APIData$result$records)
```

| _id|sarea  |sareaen       |sna              |aren                                             |sno  |tot |snaen                                    |bemp |
|---:|:------|:-------------|:----------------|:------------------------------------------------|:----|:---|:----------------------------------------|:----|
|   1|中壢區 |Zhongli Dist. |中央大學圖書館   |No.300, Zhongda Rd.                              |2001 |60  |National Central University Library      |0    |
|   2|中壢區 |Zhongli Dist. |中壢高中         |No.215, Sec. 2, Zhongyang W. Rd. (opposite)      |2002 |52  |Jhungli Senior High School               |0    |
|   3|中壢區 |Zhongli Dist. |中正公園(中美路) |No.101 to No.113, Zhongmei Rd. (opposite)        |2003 |54  |Zhongzheng Park                          |-2   |
|   4|中壢區 |Zhongli Dist. |中壢火車站(前站) |No.139, Zhonghe Rd. (opposite)                   |2004 |98  |TRA Zhongli Station (Front)              |0    |
|   5|中壢區 |Zhongli Dist. |中原大學         |No.200, Zhongbei Rd.                             |2005 |82  |Chung Yuan Christian University          |-4   |
|   6|中壢區 |Zhongli Dist. |銀河廣場         |No.48, Jiuhe 1st St. (opposite)                  |2006 |58  |Galaxy Square                            |0    |
|   7|中壢區 |Zhongli Dist. |中壢區公所       |No.380, Huanbei Rd.                              |2007 |40  |Civil Affairs Office of Zhongli District |0    |
|   8|中壢區 |Zhongli Dist. |新明橋           |No.269 to No.373, Sec. 2, Yuanhua Rd. (opposite) |2008 |58  |Xinming Bridge                           |0    |

JSON檔案解析
====================================
分析各項**地區**車站數

```r
table(APIData$result$records$sarea)
```

|Var1   | Freq|
|:------|----:|
|八德區 |    5|
|大溪區 |    2|
|大園區 |    2|
|龜山區 |   10|
|蘆竹區 |    7|
|平鎮區 |    7|
|桃園區 |   32|
|中壢區 |   35|
分析可知中壢區車站較多

JSON檔案匯入練習
====================================
type:alert
incremental:true

- 練習用資料：[「臺北市今日施工資訊」API存取](http://data.taipei/opendata/datalist/datasetMeta/outboundDesc?id=4d29818c-a3ee-425d-b88a-22ac0c24c712&rid=201d8ae8-dffc-4d17-ae1f-e58d8a95b162)
- 使用檔案匯入**範例**，將資料匯入R中
    - 提示：**fromJSON**
- 使用str()函數觀察匯入的資料
- 請問今日施工資料有幾筆觀察值？幾個欄位？

將資料框轉為JSON格式
====================================
- `jsonlite` package
- `toJSON()` 函數

```r
myjson <- toJSON(iris, pretty=TRUE)
str(myjson)
```

```
Class 'json'  chr "[\n  {\n    \"Sepal.Length\": 5.1,\n    \"Sepal.Width\": 3.5,\n    \"Petal.Length\": 1.4,\n    \"Petal.Width\": 0.2,\n    \"Spe"| __truncated__
```

網頁爬蟲 Webscraping
====================================
type:sub-section

- 不是每個網站都提供API
- 人工複製貼上?!
- 程式化的方式擷取網頁資料: **網頁爬蟲（Webscraping）**（[Webscraping Wiki](http://en.wikipedia.org/wiki/Web_scraping)）
- 可能耗費很多網頁流量和資源 －很可能被鎖IP
- 在R的處理辦法
    - 當作XML檔案處理分析
    - 使用`rvest` package輔助


網頁爬蟲 Webscraping-逐行讀取
====================================

- 直接逐行讀取 `readLines()`


```r
con <- url("http://im.cgu.edu.tw/bin/home.php")
htmlCode <-readLines(con)
close(con)
htmlCode[3:5]
```

```
[1] "<head>"                                                                                                                                       
[2] "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />"                                                                    
[3] "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=EmulateIE7\" /><meta name=\"keywords\" content=\"請填寫網站關鍵記事，用半角逗號(,)隔開\" />"
```

網頁爬蟲 Webscraping-XML工具
====================================
或是使用XML工具分析擷取網頁 (`XML` package)


```r
html <- htmlParse("http://im.cgu.edu.tw/bin/home.php")
xpathSApply(html, "//title", xmlValue)
```

```
[1] "長庚大學 資訊管理學系 "
```

網頁爬蟲 Webscraping-逐行讀取
====================================
讀取完網頁後，使用用XML工具與xpath分析擷取網頁 (`XML` package)

```r
xpathSApply(html, "//span[@class='ptname ']", xmlValue)
```

```
 [1] "大數據資料科學與產業應用學程"      
 [2] "資訊與醫療安全學程"                
 [3] "物聯網產業創新應用學程"            
 [4] "機器人智能互動與創新應用(暑期)學程"
 [5] "校務資訊系統"                      
 [6] "人事教育訓練資訊網"                
 [7] "畢業校友登錄系統"                  
 [8] "碩博士論文網"                      
 [9] "資管系導師名單"                    
[10] "國內資管系所"                      
[11] "資管系內部行政系統"                
[12] "資管系分機表"                      
[13] "資管系學會"                        
[14] "管理學院"                          
[15] "醫務管理學系"                      
[16] "工商管理學系"                      
[17] "工業設計學系"                      
[18] "企業管理研究所博士班"              
[19] "商管專業學院"                      
[20] "長庚大學行事曆"                    
```

網頁爬蟲 Webscraping-rvest
====================================

載入[rvest](https://github.com/hadley/rvest)套件後，經由以下步驟進行網站解析：

- 使用`read_html(“欲擷取的網站網址”)`函數讀取網頁
- 使用`html_nodes()`函數擷取所需內容 (條件為CSS或xpath標籤)
- 使用`html_text()`函數處理/清洗擷取內容，留下需要的資料
- 使用`html_attr()`函數擷取資料參數（如連結url）

CSS Selector 語法介紹
====================================
- [參考資料](https://www.w3schools.com/cssref/css_selectors.asp)
    - **.**xxx：select elements with class="xxx"
    - **#**xxx：select elements with id="xxx"
    - **[**yyy**]**：select elements with attribute yyy
    - **[**yyy=zzz**]**：select elements with attribute yyy="zzz"
    
網頁爬蟲 Webscraping-rvest
====================================

```r
library(rvest) ##載入
Repoterurl<-"https://www.twreporter.org/"
news_title <- read_html(Repoterurl) %>% html_nodes(".hzKrPP") %>% html_text()
news_url <- read_html(Repoterurl) %>% html_nodes(".hzKrPP a") %>% html_attr("href")
news <- data.frame(title = news_title, url=news_url)
head(news)
```

```
                                                     title                                                    url
1                           陳藹文／追傳奇的傳奇：夏子之光                                  /a/bookreview-natsuko
2                   再見東聲：頭份最後一間老戲院的映演歲月                  /a/opinion-goodbye-dong-sheng-theater
```

網頁爬蟲 Webscraping-rvest
====================================
- 擷取條件的撰寫會因網頁語法不同而有差異
- 使用**Google Chrome開發工具**輔助觀察擷取資料的條件
    - 或使用**SelectorGadget**輔助
    - 或使用**xpath-helper**輔助xpath標籤的擷取
- 觀察需要擷取的資料所在HTML片段
    - 且css class為`latest-section__ItemFrame-gk5lu9-1 hzKrPP`

```
<div class="latest-section__ItemFrame-gk5lu9-1 hzKrPP"><a href="/a/bookreview-natsuko"><div class="hover-effect__HoverEffect-s1mpr2b0-0 kfSlYe"><div class="latest-section__ImageFrame-gk5lu9-2 jUFDxW"><div class="img-wrapper__ImgObjectFit-ketl5c-0 jYnMAC"><img alt="陳藹文／追傳奇的傳奇：夏子之光" src="https://www.twreporter.org/images/20180305174703-97e2a0058b900aec1df1fce4ecdd876f-mobile.png" srcSet="" style="transform:translateZ(0)"/></div></div><div class="latest-section__ContentFrame-gk5lu9-3 hlpTZa"><div class="latest-section__Category-gk5lu9-4 kniurW category-name__CategoryName-s1o0c9ma-0 ivjNw">評論</div><div class="latest-section__Title-gk5lu9-5 clMzIT">陳藹文／追傳奇的傳奇：夏子之光</div></div></div></a></div>
....
```

網頁爬蟲 DCard實作 -1
====================================

```r
library(rvest) ##(爬蟲結果不代表本人意見)
DCardCGU<-"https://www.dcard.tw/f/cgu"
DCardContent<-read_html(DCardCGU)
post_title <- DCardContent %>% html_nodes(".PostEntry_title_H5o4d") %>% html_text()
post_contentShort<- DCardContent %>% html_nodes(".PostEntry_excerpt_2eHlN") %>% html_text()
post_author<- DCardContent %>% html_nodes(".PostAuthor_root_3vAJf") %>% html_text()
```

網頁爬蟲 DCard實作 -2
====================================

```r
##(爬蟲結果不代表本人意見)
post_like<- DCardContent %>% html_nodes(".Like_counter_1enlP") %>% html_text()
post_url <- DCardContent %>% html_nodes(".PostEntry_root_V6g0r") %>% html_attr("href")
DCardCGU_posts <- 
    data.frame(title = post_title,
               author=post_author, 
               content=post_contentShort, 
               likeN=post_like,
               url=paste0("https://www.dcard.tw",post_url))
```

網頁爬蟲 DCard實作 -3
====================================

```r
DCardCGU_posts[1:4,c("title","author","likeN")]
```

|title                     |author                      |likeN |
|:-------------------------|:---------------------------|:-----|
|學弟認命當墊底吧 我想過啊 |長庚大學 化工與材料工程學系 |36    |
|假賣二手 真坑人 ㄏㄏ      |長庚大學                    |14    |
|校車                      |長庚大學                    |6     |
|校車司機                  |長庚大學                    |0     |


進階爬蟲
====================================
- 瀑布式網頁爬蟲
    - 觀察Google Chrome 開發者工具，在Network內找到api呼叫方式
    - 搭配使用RSelenium 模擬瀏覽狀態
    - 操作範例 [爬DCard實作R Code](https://github.com/CGUIM-BigDataAnalysis/BigDataCGUIM/blob/master/105/RSelenium_rvest.md)


爬蟲練習
====================================
type:alert

- [Ptt Tech_Job 版](https://www.ptt.cc/bbs/Tech_Job/index.html)
- 試著爬出所有**標題**
- 爬出的第三個標題是？


網頁爬蟲 再想想？
====================================
incremental:true

- 如何爬評論跟內文呢？
- 其實...DCard是有API的
    - https://www.dcard.tw/_api/forums/cgu/posts
    - https://www.dcard.tw/_api/posts/228454694
    - https://www.dcard.tw/_api/posts/228454694/comments
- 隱私問題 （2016年的OkCupid事件）
    - [70,000 OkCupid Users Just Had Their Data Published](https://motherboard.vice.com/en_us/article/70000-okcupid-users-just-had-their-data-published)

其他爬蟲相關參考資源
====================================
- [網路爬蟲實作 - 用 r 語言打造自己的爬蟲程式](https://www.slideshare.net/secret/mdfHLPgvIW1kPR)
- [rvest GitHub](https://github.com/hadley/rvest)
- R Bloggers 有很多[爬蟲範例](http://www.r-bloggers.com/?s=Web+Scraping)（英文）
- [Ptt爬蟲實作](http://bryannotes.blogspot.tw/2014/08/r-ptt-wantedsocial-network-analysis.html)
- [大數學堂 網頁爬蟲課程](http://www.largitdata.com/course_list/1)


從Facebook匯入
====================================
type:section
- Graph API in R
- Rfacebook package

Graph API in R
====================================
type:sub-section

- [Graph API](https://developers.facebook.com/docs/graph-api?locale=zh_TW)
    - 根據篩選條件，回傳JSON格式的資料
- [Graph API Explorer](https://developers.facebook.com/tools/explorer/)
    - 測試資料撈取方法和結果
- 必須要取得自己的**access token** (存取權杖)
    - 可在[Graph API Explorer](https://developers.facebook.com/tools/explorer/)視窗右上角的**Get Token**按鈕取得
    - [官方文件](https://developers.facebook.com/docs/facebook-login/access-tokens/?locale=zh_TW)

Graph API in R
====================================

```r
library(httr)
token<-"your access token" #將access token複製到此處 
FBData = GET(
    paste0("https://graph.facebook.com/v2.12/tsaiingwen?fields=posts%7Bmessage%7D&access_token=",
           token))
names(FBData)
```

```
## [1] "url"         "status_code" "headers"     "all_headers" "cookies"     "content"     "date"       
## [8] "times"       "request"     "handle"    
```

Graph API in R
====================================

```r
json1 = content(FBData)
names(json1)
```
```
## [1] "posts" "id"
```

```r
names(json1$posts)
```
```
## [1] "data"   "paging"
```
Graph API in R
====================================

```r
head(json1$posts$data,2)
```
```
[[1]]
[[1]]$message
[1] "「我們是寫歷史的那張白紙。」在國防部軍情局牆上的這句話，意思是不論歷史如何演變，情報人員的貢獻和血淚，往往不為外人所知，只能留白。軍情局設置了一面無名英雄紀念碑，就是為了紀念數千名弟兄姊妹的血和淚。\n\n今天我到軍情局勉勵官兵，並且在紀念碑前致敬，感謝這些弟兄姊妹用生命守護台灣的自由民主。\n\n軍情局近來也持續在內部推動政治檔案的整理工作。在民主時代，把社會的信任和支持建立起來，情報工作的推展會更加順利，期許軍情局繼續努力。"

[[1]]$id
[1] "46251501064_10154992163696065"
```

Graph API in R
====================================

```r
json1$posts$data[[1]]$message
```
```
[1] "「我們是寫歷史的那張白紙。」在國防部軍情局牆上的這句話，意思是不論歷史如何演變，情報人員的貢獻和血淚，往往不為外人所知，只能留白。軍情局設置了一面無名英雄紀念碑，就是為了紀念數千名弟兄姊妹的血和淚。\n\n今天我到軍情局勉勵官兵，並且在紀念碑前致敬，感謝這些弟兄姊妹用生命守護台灣的自由民主。\n\n軍情局近來也持續在內部推動政治檔案的整理工作。在民主時代，把社會的信任和支持建立起來，情報工作的推展會更加順利，期許軍情局繼續努力。"
```



Rfacebook package
====================================
type:sub-section

使用 Rfacebook 取得 `tsaiingwen` 粉絲頁的資料

```r
library(Rfacebook) #初次使用須先安裝
token<-"your token" #將token複製到此處 
getPage("tsaiingwen", token,n = 5)
```
實際操作

```
4 posts       from_id           from_name
1 46251501064 蔡英文 Tsai Ing-wen
2 46251501064 蔡英文 Tsai Ing-wen
3 46251501064 蔡英文 Tsai Ing-wen
4 46251501064 蔡英文 Tsai Ing-wen
```

Rfacebook package練習
====================================
type:alert
incremental:true
- 取得Facebook access token
- 使用Rfacebook package取得**CGSGA 長庚學生會**粉絲頁面的前五筆資料
- 第一筆資料的likes_count是多少?
- 第二筆資料的shares_count是多少?


Rfacebook package
====================================
- 每次擷取資料的比數有上限（大概30筆）
- 如需取得更多資料: 使用迴圈協助
    -  **since** 和 **until**參數，可設定資料擷取區間。
- 先取得日期向量，供後續迴圈做使用

```r
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2018-01-01"),lastDate,by="5 days")
DateVectorStr<-as.character(DateVector)
DateVectorStr
```
```
## "2017-01-01" "2017-01-06" "2017-01-11" "2017-01-16" "2017-01-21" "2017-01-26" "2017-01-31" "2017-02-05"
```

Rfacebook package
====================================
利用上述日期向量資料，搭配迴圈，依序設定**since** 和 **until**參數

```r
totalPage<-NULL
token<-'your token'
for(i in 1:(length(DateVectorStr)-1)){
    tempPage<-getPage("tsaiingwen", token,
                since = DateVectorStr[i],
                until = DateVectorStr[i+1])
    totalPage<-rbind(totalPage,tempPage)
}
nrow(totalPage)
```
```
## [1] 42
```


Rfacebook 提供的其他函數
====================================
- getUsers()
- getPost()
- searchFacebook()
- Check https://github.com/pablobarbera/Rfacebook
- ?Rfacebook


Facebook資料擷取練習
====================================
type:alert
incremental:true

- 桃園捷運 Taoyuan MRT (TaoyuanMRT) 粉絲頁
- 分別擷取以下兩段時間的資料
    - 2017/2/16~20 (自由試乘開始)
    - 2017/3/2~6 (正式通車)
- 比較兩區間平均按讚次數，留言次數與分享次數，觀察民眾對粉絲頁的熱度

Facebook資料擷取練習
====================================
type:alert
incremental:true

- 嘗試看說明文件，使用以下函式
    - getUsers()
    - getPost()
    - searchFacebook()

- 檢查每個函式回傳的資料，各有幾個欄位？

資料匯出
====================================
type:section
- 文字檔 .txt
- CSV檔 .csv
- R物件 .rds


文字檔 .txt write.table()
====================================
type:sub-section


```r
write.table(iris,file="iris.txt",sep=",",
            row.names = F,col.names = T)
```
- 要匯出的資料
- `file` 檔案名稱
- `append` T/F T:在檔案後加字，F:直接覆蓋檔案 (預設F)
- `quote` 是否需要用雙引號將字串包起 (預設T)
- `sep` 分隔符號 (預設空白)
- `row.names` T/F 是否需要輸出row names
- `col.names` T/F 是否需要輸出column names
- `fileEncoding` 編碼設定

write.table() 練習
====================================
type:alert
incremental:true

- 將剛剛擷取的桃園捷運 Taoyuan MRT 粉絲頁資料存成tab分隔的.txt檔案

CSV檔 .csv
====================================
type:sub-section

與`write.table()`類似，使用`write.csv()`函數寫入檔案

```r
write.csv(iris,file="iris.csv",row.names = F)
```

R物件 .rds
====================================
type:sub-section

若是要在R的環境繼續使用，建議匯出成R物件檔案(.rds)

```r
saveRDS(iris,"iris.rds")
```

saveRDS() 練習
====================================
type:alert
incremental:true

- 將剛剛擷取的桃園捷運 Taoyuan MRT 粉絲頁資料存成R物件檔案(.rds)
- 比較與txt檔案大小的差異

